from googleapiclient.discovery import build
import pandas as pd
import time
import datetime
import isodate  # duration ì²˜ë¦¬ìš©

# âœ… API Key ì…ë ¥
api_key = 'API_KEY'
youtube = build('youtube', 'v3', developerKey=api_key)

# âœ… ë‚ ì§œ ê³„ì‚° (ìµœê·¼ 3ê°œì›”)
today = datetime.datetime.utcnow()
three_months_ago = today - datetime.timedelta(days=90)
published_after = three_months_ago.isoformat("T") + "Z"  # RFC3339 í˜•ì‹

# âœ… ì˜ìƒ ID ìˆ˜ì§‘
def get_video_ids(keyword, max_results=50, page_token=None):
    request = youtube.search().list(
        part='id,snippet',
        q=keyword,
        type='video',
        order='date',
        publishedAfter=published_after,
        maxResults=max_results,
        pageToken=page_token
    )
    response = request.execute()
    video_data = []
    for item in response['items']:
        video_data.append({
            'videoId': item['id']['videoId'],
            'channelId': item['snippet']['channelId']
        })
    next_page_token = response.get('nextPageToken')
    return video_data, next_page_token

# âœ… ì˜ìƒ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
def get_video_details(video_ids):
    request = youtube.videos().list(
        part='snippet,contentDetails,statistics',
        id=','.join(video_ids)
    )
    response = request.execute()
    
    result = []
    for item in response['items']:
        snippet = item['snippet']
        stats = item.get('statistics', {})
        details = item['contentDetails']
        try:
            # durationì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
            duration_seconds = isodate.parse_duration(details['duration']).total_seconds()
        except:
            duration_seconds = 0

        result.append({
            'videoId': item['id'],
            'title': snippet.get('title'),
            'description': snippet.get('description'),
            'publishedAt': snippet.get('publishedAt'),
            'tags': snippet.get('tags', []),
            'categoryId': snippet.get('categoryId'),
            'thumbnail': snippet['thumbnails']['high']['url'],
            'viewCount': int(stats.get('viewCount', 0)),
            'likeCount': int(stats.get('likeCount', 0)),
            'duration': duration_seconds,
            'channelId': snippet.get('channelId')
        })
    return result

# âœ… ì±„ë„ ì •ë³´ ìˆ˜ì§‘
def get_channel_details(channel_ids):
    request = youtube.channels().list(
        part='statistics',
        id=','.join(channel_ids)
    )
    response = request.execute()
    channel_stats = {}
    for item in response['items']:
        stats = item['statistics']
        channel_stats[item['id']] = {
            'subscriberCount': int(stats.get('subscriberCount', 0)),
            'channelViewCount': int(stats.get('viewCount', 0)),
            'videoCount': int(stats.get('videoCount', 0))
        }
    return channel_stats

# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    keywords = ['ë°œë¡œë€íŠ¸','ë°°í‹€ê·¸ë¼ìš´ë“œ','ë§ˆì¸í¬ë˜í”„íŠ¸','ë¦¬ê·¸ ì˜¤ë¸Œ ë ˆì „ë“œ']
    all_video_data = []
    collected_video_ids = []
    max_pages = 3  # í‚¤ì›Œë“œë‹¹ í˜ì´ì§€ ìˆ˜

    for keyword in keywords:
        print(f"\nğŸ” [í‚¤ì›Œë“œ: {keyword}] ì˜ìƒ ID ìˆ˜ì§‘ ì¤‘...")
        next_page_token = None
        for _ in range(max_pages):
            try:
                video_infos, next_page_token = get_video_ids(keyword, 50, next_page_token)
                collected_video_ids.extend(video_infos)
                print(f"âœ… {len(video_infos)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                time.sleep(1)
                if not next_page_token:
                    break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break

    print(f"\nğŸ¯ ì´ {len(collected_video_ids)}ê°œì˜ ì˜ìƒ ID ìˆ˜ì§‘ ì™„ë£Œ.")

    # ì˜ìƒ + ì±„ë„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
    final_data = []
    for i in range(0, len(collected_video_ids), 50):
        batch = collected_video_ids[i:i+50]
        video_ids = [v['videoId'] for v in batch]
        channel_ids = list(set([v['channelId'] for v in batch]))
        try:
            video_details = get_video_details(video_ids)
            channel_stats = get_channel_details(channel_ids)

            for video in video_details:
                channel_id = video['channelId']
                channel_info = channel_stats.get(channel_id, {})
                video.update({
                    'subscriberCount': channel_info.get('subscriberCount'),
                    'channelViewCount': channel_info.get('channelViewCount'),
                    'videoCount': channel_info.get('videoCount')
                })
                final_data.append(video)

            print(f"ğŸ“¦ ëˆ„ì  ìˆ˜ì§‘: {len(final_data)}ê°œ")
            time.sleep(1)
        except Exception as e:
            print(f"âŒ ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # âœ… ë¡±í¼ í•„í„° (60ì´ˆ ì´ˆê³¼ë§Œ)
    df = pd.DataFrame(final_data)
    df = df[df['duration'] > 60]  # ì‡¼ì¸  ì œê±°

    # âœ… ì¡°íšŒìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    df_sorted = df.sort_values(by='viewCount', ascending=False)

    # âœ… ì €ì¥
    df_sorted.to_csv('youtube_view_prediction_data.csv', index=False, encoding='utf-8-sig')
    print(f"\nâœ… ìµœì¢… {len(df_sorted)}ê°œì˜ ë¡±í¼ ì˜ìƒì´ ì¡°íšŒìˆ˜ ìˆœìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
